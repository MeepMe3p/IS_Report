{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ad3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 18:57:02.485650: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 18:57:02.653627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746356222.724902    1386 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746356222.748896    1386 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 18:57:02.891554: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.appliications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC,Precision,Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,Tensorboard\n",
    "\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images\n",
    "# base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "# inputs = layers.Input(shape=(224,224,1))\n",
    "# x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "# x = base_model(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# outputs = layers.Dense(8,activation='sigmoid')(x)\n",
    "\n",
    "# model = models.Model(inputs,outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a26607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746349350.213010    1152 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1746349350.226281    1152 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,967</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m8,967\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,058,568</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,058,568\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,707,885</span> (14.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,707,885\u001b[0m (14.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,683</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m350,683\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# # Use mixed precision\n",
    "# # https://keras.io/api/mixed_precision/\n",
    "# set_global_policy('mixed_float16')\n",
    "\n",
    "# # Clear GPU memory\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "#     base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "#     inputs = layers.Input(shape=(224,224,1))\n",
    "#     x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "#     # x = layers.Lambda(lambda x: tf.repeat(x, 3, axis=-1))(inputs)\n",
    "#     x = base_model(x)\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     # x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "#     # base_model.\n",
    "#     outputs = layers.Dense(7,activation='sigmoid')(x)\n",
    "#     for layer in base_model.layers[:-119]:\n",
    "#         layer.trainable = False\n",
    "\n",
    "\n",
    "#     # model.add\n",
    "\n",
    "#     model = models.Model(inputs,outputs)\n",
    "\n",
    "    \n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674090df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(base_model.layers[-119:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-5), loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"\n",
    "#                                                                       # , \"val_accuracy\"\n",
    "#                                                                     #   ,AUC(), Precision(),Recall()\n",
    "#                                                                       ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.path.exists('/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a25fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "X_train = np.load(\"../data/numpy/X_train.npy\")\n",
    "Y_train = np.load(\"../data/numpy/Y_train.npy\")\n",
    "\n",
    "X_val = np.load(\"../data/numpy/X_valid.npy\")\n",
    "Y_val = np.load(\"../data/numpy/Y_valid.npy\")\n",
    "\n",
    "\n",
    "# X_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_train.npy\")\n",
    "# Y_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy\")\n",
    "\n",
    "# X_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_valid.npy\")\n",
    "# Y_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_valid.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc60e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d2f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 0.8576 - loss: 0.3423\n",
      "Epoch 1: val_loss improved from inf to 0.33700, saving model to ../checkpoint/model_01.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 88ms/step - binary_accuracy: 0.8576 - loss: 0.3423 - val_binary_accuracy: 0.8582 - val_loss: 0.3370\n",
      "Epoch 2/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8581 - loss: 0.3395\n",
      "Epoch 2: val_loss improved from 0.33700 to 0.32906, saving model to ../checkpoint/model_02.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8581 - loss: 0.3395 - val_binary_accuracy: 0.8600 - val_loss: 0.3291\n",
      "Epoch 3/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.8585 - loss: 0.3384\n",
      "Epoch 3: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 64ms/step - binary_accuracy: 0.8585 - loss: 0.3384 - val_binary_accuracy: 0.8598 - val_loss: 0.3315\n",
      "Epoch 4/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.8592 - loss: 0.3367\n",
      "Epoch 4: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - binary_accuracy: 0.8592 - loss: 0.3367 - val_binary_accuracy: 0.8543 - val_loss: 0.3392\n",
      "Epoch 5/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8589 - loss: 0.3351\n",
      "Epoch 5: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 65ms/step - binary_accuracy: 0.8589 - loss: 0.3351 - val_binary_accuracy: 0.8580 - val_loss: 0.3304\n",
      "Epoch 6/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.8597 - loss: 0.3327\n",
      "Epoch 6: val_loss improved from 0.32906 to 0.32865, saving model to ../checkpoint/model_06.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 65ms/step - binary_accuracy: 0.8597 - loss: 0.3327 - val_binary_accuracy: 0.8573 - val_loss: 0.3286\n",
      "Epoch 7/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8602 - loss: 0.3317\n",
      "Epoch 7: val_loss improved from 0.32865 to 0.32458, saving model to ../checkpoint/model_07.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8602 - loss: 0.3317 - val_binary_accuracy: 0.8618 - val_loss: 0.3246\n",
      "Epoch 8/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8602 - loss: 0.3294\n",
      "Epoch 8: val_loss improved from 0.32458 to 0.32229, saving model to ../checkpoint/model_08.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8602 - loss: 0.3294 - val_binary_accuracy: 0.8580 - val_loss: 0.3223\n",
      "Epoch 9/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8617 - loss: 0.3267\n",
      "Epoch 9: val_loss improved from 0.32229 to 0.32027, saving model to ../checkpoint/model_09.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8617 - loss: 0.3267 - val_binary_accuracy: 0.8602 - val_loss: 0.3203\n",
      "Epoch 10/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8608 - loss: 0.3263\n",
      "Epoch 10: val_loss improved from 0.32027 to 0.31793, saving model to ../checkpoint/model_10.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8608 - loss: 0.3263 - val_binary_accuracy: 0.8588 - val_loss: 0.3179\n",
      "Epoch 11/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8620 - loss: 0.3239\n",
      "Epoch 11: val_loss improved from 0.31793 to 0.31459, saving model to ../checkpoint/model_11.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8620 - loss: 0.3239 - val_binary_accuracy: 0.8594 - val_loss: 0.3146\n",
      "Epoch 12/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8617 - loss: 0.3238\n",
      "Epoch 12: val_loss improved from 0.31459 to 0.31068, saving model to ../checkpoint/model_12.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - binary_accuracy: 0.8617 - loss: 0.3238 - val_binary_accuracy: 0.8651 - val_loss: 0.3107\n",
      "Epoch 13/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8631 - loss: 0.3220\n",
      "Epoch 13: val_loss did not improve from 0.31068\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8631 - loss: 0.3220 - val_binary_accuracy: 0.8616 - val_loss: 0.3117\n",
      "Epoch 14/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8626 - loss: 0.3205\n",
      "Epoch 14: val_loss improved from 0.31068 to 0.30636, saving model to ../checkpoint/model_14.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8626 - loss: 0.3204 - val_binary_accuracy: 0.8686 - val_loss: 0.3064\n",
      "Epoch 15/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8638 - loss: 0.3174\n",
      "Epoch 15: val_loss did not improve from 0.30636\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8638 - loss: 0.3174 - val_binary_accuracy: 0.8655 - val_loss: 0.3070\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    )\n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    # batch_size = 8,\n",
    "    verbose = 1,\n",
    "    callbacks = my_callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data = (X_val, Y_val),\n",
    "#     epochs = 10,\n",
    "#     batch_size = 8,\n",
    "#     verbose = 1\n",
    "#     )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=80,\n",
    "#     # batch_size = 8,\n",
    "#     verbose = 1,\n",
    "#     callbacks = my_callbacks\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.load(\"../data/numpy/X_test.npy\")\n",
    "# Y_test = np.load(\"../data/numpy/Y_test.npy\")\n",
    "# results = model.evaluate(X_test,Y_test,batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d149807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test[:3])\n",
    "# print(predictions.shape)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.load_model(\"../checkpoint/model_02.keras\")\n",
    "# print(len(model.layers))\n",
    "# # for layer in models.layer[:]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f0dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746129921.821372    1411 service.cc:148] XLA service 0x7f30b4012fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746129921.823315    1411 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2050, Compute Capability 8.6\n",
      "2025-05-02 04:05:22.374715: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746129925.870926    1411 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-02 04:05:29.970871: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14694', 364 bytes spill stores, 472 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/1574\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 82ms/step - binary_accuracy: 0.8259 - loss: 0.4018   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746129967.545572    1411 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8646 - loss: 0.3186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 04:07:56.658199: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14694', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2025-05-02 04:07:59.206706: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[5,32,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,112,112]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-05-02 04:07:59.340939: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.13433351s\n",
      "Trying algorithm eng4{} for conv (f32[5,32,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,112,112]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 0.8646 - loss: 0.3186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 04:08:41.066743: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: val_loss improved from inf to 0.31291, saving model to ../checkpoint/model_15.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 105ms/step - binary_accuracy: 0.8646 - loss: 0.3186 - val_binary_accuracy: 0.8604 - val_loss: 0.3129\n",
      "Epoch 16/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8641 - loss: 0.3173\n",
      "Epoch 16: val_loss improved from 0.31291 to 0.30392, saving model to ../checkpoint/model_16.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8641 - loss: 0.3173 - val_binary_accuracy: 0.8682 - val_loss: 0.3039\n",
      "Epoch 17/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8647 - loss: 0.3157\n",
      "Epoch 17: val_loss did not improve from 0.30392\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - binary_accuracy: 0.8647 - loss: 0.3157 - val_binary_accuracy: 0.8672 - val_loss: 0.3049\n",
      "Epoch 18/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8656 - loss: 0.3131\n",
      "Epoch 18: val_loss did not improve from 0.30392\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - binary_accuracy: 0.8656 - loss: 0.3131 - val_binary_accuracy: 0.8651 - val_loss: 0.3048\n",
      "Epoch 19/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8649 - loss: 0.3143\n",
      "Epoch 19: val_loss did not improve from 0.30392\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8649 - loss: 0.3143 - val_binary_accuracy: 0.8633 - val_loss: 0.3054\n",
      "Epoch 20/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8660 - loss: 0.3113\n",
      "Epoch 20: val_loss improved from 0.30392 to 0.30332, saving model to ../checkpoint/model_20.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 66ms/step - binary_accuracy: 0.8660 - loss: 0.3113 - val_binary_accuracy: 0.8647 - val_loss: 0.3033\n",
      "Epoch 21/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8678 - loss: 0.3091\n",
      "Epoch 21: val_loss improved from 0.30332 to 0.30081, saving model to ../checkpoint/model_21.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - binary_accuracy: 0.8678 - loss: 0.3091 - val_binary_accuracy: 0.8694 - val_loss: 0.3008\n",
      "Epoch 22/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8668 - loss: 0.3089\n",
      "Epoch 22: val_loss did not improve from 0.30081\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 67ms/step - binary_accuracy: 0.8668 - loss: 0.3089 - val_binary_accuracy: 0.8686 - val_loss: 0.3019\n",
      "Epoch 23/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8677 - loss: 0.3067\n",
      "Epoch 23: val_loss did not improve from 0.30081\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - binary_accuracy: 0.8677 - loss: 0.3067 - val_binary_accuracy: 0.8694 - val_loss: 0.3008\n",
      "Epoch 24/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8689 - loss: 0.3038\n",
      "Epoch 24: val_loss did not improve from 0.30081\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8689 - loss: 0.3038 - val_binary_accuracy: 0.8676 - val_loss: 0.3022\n",
      "Epoch 25/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8694 - loss: 0.3036\n",
      "Epoch 25: val_loss improved from 0.30081 to 0.30074, saving model to ../checkpoint/model_25.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8694 - loss: 0.3036 - val_binary_accuracy: 0.8686 - val_loss: 0.3007\n",
      "Epoch 26/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8703 - loss: 0.3014\n",
      "Epoch 26: val_loss did not improve from 0.30074\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - binary_accuracy: 0.8703 - loss: 0.3014 - val_binary_accuracy: 0.8684 - val_loss: 0.3020\n",
      "Epoch 27/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8707 - loss: 0.2995\n",
      "Epoch 27: val_loss did not improve from 0.30074\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 67ms/step - binary_accuracy: 0.8707 - loss: 0.2995 - val_binary_accuracy: 0.8678 - val_loss: 0.3027\n",
      "Epoch 28/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8701 - loss: 0.2991\n",
      "Epoch 28: val_loss did not improve from 0.30074\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8701 - loss: 0.2991 - val_binary_accuracy: 0.8672 - val_loss: 0.3008\n",
      "Epoch 29/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8721 - loss: 0.2976\n",
      "Epoch 29: val_loss did not improve from 0.30074\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - binary_accuracy: 0.8721 - loss: 0.2976 - val_binary_accuracy: 0.8698 - val_loss: 0.3015\n",
      "Epoch 30/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8728 - loss: 0.2960\n",
      "Epoch 30: val_loss did not improve from 0.30074\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8728 - loss: 0.2960 - val_binary_accuracy: 0.8674 - val_loss: 0.3030\n",
      "Epoch 31/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8721 - loss: 0.2956\n",
      "Epoch 31: val_loss improved from 0.30074 to 0.29913, saving model to ../checkpoint/model_31.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8721 - loss: 0.2956 - val_binary_accuracy: 0.8721 - val_loss: 0.2991\n",
      "Epoch 32/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8740 - loss: 0.2936\n",
      "Epoch 32: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8740 - loss: 0.2936 - val_binary_accuracy: 0.8692 - val_loss: 0.3036\n",
      "Epoch 33/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8747 - loss: 0.2898\n",
      "Epoch 33: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8748 - loss: 0.2898 - val_binary_accuracy: 0.8710 - val_loss: 0.3017\n",
      "Epoch 34/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8748 - loss: 0.2898\n",
      "Epoch 34: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - binary_accuracy: 0.8748 - loss: 0.2898 - val_binary_accuracy: 0.8655 - val_loss: 0.3065\n",
      "Epoch 35/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8762 - loss: 0.2876\n",
      "Epoch 35: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8762 - loss: 0.2876 - val_binary_accuracy: 0.8684 - val_loss: 0.3028\n",
      "Epoch 36/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8773 - loss: 0.2850\n",
      "Epoch 36: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - binary_accuracy: 0.8773 - loss: 0.2850 - val_binary_accuracy: 0.8672 - val_loss: 0.3052\n",
      "Epoch 37/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8774 - loss: 0.2842\n",
      "Epoch 37: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 68ms/step - binary_accuracy: 0.8774 - loss: 0.2842 - val_binary_accuracy: 0.8688 - val_loss: 0.3053\n",
      "Epoch 38/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8792 - loss: 0.2813\n",
      "Epoch 38: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - binary_accuracy: 0.8792 - loss: 0.2813 - val_binary_accuracy: 0.8676 - val_loss: 0.3073\n",
      "Epoch 39/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8778 - loss: 0.2815\n",
      "Epoch 39: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - binary_accuracy: 0.8778 - loss: 0.2815 - val_binary_accuracy: 0.8676 - val_loss: 0.3105\n",
      "Epoch 40/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8800 - loss: 0.2791\n",
      "Epoch 40: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - binary_accuracy: 0.8800 - loss: 0.2791 - val_binary_accuracy: 0.8690 - val_loss: 0.3058\n",
      "Epoch 41/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8797 - loss: 0.2784\n",
      "Epoch 41: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - binary_accuracy: 0.8797 - loss: 0.2784 - val_binary_accuracy: 0.8682 - val_loss: 0.3090\n",
      "Epoch 42/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8818 - loss: 0.2749\n",
      "Epoch 42: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8818 - loss: 0.2749 - val_binary_accuracy: 0.8674 - val_loss: 0.3113\n",
      "Epoch 43/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - binary_accuracy: 0.8821 - loss: 0.2732\n",
      "Epoch 43: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8821 - loss: 0.2732 - val_binary_accuracy: 0.8682 - val_loss: 0.3128\n",
      "Epoch 44/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8845 - loss: 0.2706\n",
      "Epoch 44: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - binary_accuracy: 0.8845 - loss: 0.2706 - val_binary_accuracy: 0.8657 - val_loss: 0.3135\n",
      "Epoch 45/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8844 - loss: 0.2699\n",
      "Epoch 45: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - binary_accuracy: 0.8844 - loss: 0.2699 - val_binary_accuracy: 0.8661 - val_loss: 0.3163\n",
      "Epoch 46/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8850 - loss: 0.2670\n",
      "Epoch 46: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 68ms/step - binary_accuracy: 0.8850 - loss: 0.2670 - val_binary_accuracy: 0.8663 - val_loss: 0.3199\n",
      "Epoch 47/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8875 - loss: 0.2637\n",
      "Epoch 47: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - binary_accuracy: 0.8875 - loss: 0.2637 - val_binary_accuracy: 0.8663 - val_loss: 0.3194\n",
      "Epoch 48/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8873 - loss: 0.2618\n",
      "Epoch 48: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 66ms/step - binary_accuracy: 0.8873 - loss: 0.2618 - val_binary_accuracy: 0.8655 - val_loss: 0.3197\n",
      "Epoch 49/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8887 - loss: 0.2607\n",
      "Epoch 49: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8887 - loss: 0.2607 - val_binary_accuracy: 0.8649 - val_loss: 0.3227\n",
      "Epoch 50/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8889 - loss: 0.2601\n",
      "Epoch 50: val_loss did not improve from 0.29913\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8889 - loss: 0.2601 - val_binary_accuracy: 0.8665 - val_loss: 0.3270\n"
     ]
    }
   ],
   "source": [
    "# continue\n",
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    )\n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "model = load_model(\"../checkpoint/model_14.keras\")\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     initial_epoch = 14,\n",
    "#     epochs=50,\n",
    "#     # batch_size = 8,\n",
    "#     verbose = 1,\n",
    "#     callbacks = my_callbacks\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f48c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"../checkpoint/saved_model.keras\")\n",
    "model = models.load_model(\"../checkpoint/model_31.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33702974",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.layers[2].layers[0].trainable = False\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m210\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model.layers[2].layers[0].trainable = False\n",
    "base_model = model.layers[2]\n",
    "\n",
    "\n",
    "for layer in base_model.layers[:210]:\n",
    "    layer.trainable =False\n",
    "\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if layer.trainable:\n",
    "        print(i, layer.name, layer.trainable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffe0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - binary_accuracy: 0.8712 - loss: 0.2989\n",
      "Epoch 32: val_loss improved from inf to 0.29875, saving model to ../checkpoint/model_32.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 76ms/step - binary_accuracy: 0.8712 - loss: 0.2989 - val_binary_accuracy: 0.8702 - val_loss: 0.2988 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - binary_accuracy: 0.8711 - loss: 0.2965\n",
      "Epoch 33: val_loss improved from 0.29875 to 0.29822, saving model to ../checkpoint/model_33.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 60ms/step - binary_accuracy: 0.8711 - loss: 0.2965 - val_binary_accuracy: 0.8684 - val_loss: 0.2982 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.8735 - loss: 0.2942\n",
      "Epoch 34: val_loss did not improve from 0.29822\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 59ms/step - binary_accuracy: 0.8735 - loss: 0.2942 - val_binary_accuracy: 0.8694 - val_loss: 0.2985 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.8730 - loss: 0.2956\n",
      "Epoch 35: val_loss improved from 0.29822 to 0.29783, saving model to ../checkpoint/model_35.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 57ms/step - binary_accuracy: 0.8730 - loss: 0.2956 - val_binary_accuracy: 0.8710 - val_loss: 0.2978 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.8752 - loss: 0.2913\n",
      "Epoch 36: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - binary_accuracy: 0.8752 - loss: 0.2913 - val_binary_accuracy: 0.8676 - val_loss: 0.2996 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.8758 - loss: 0.2911\n",
      "Epoch 37: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.8758 - loss: 0.2911 - val_binary_accuracy: 0.8692 - val_loss: 0.2998 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.8748 - loss: 0.2912\n",
      "Epoch 38: val_loss did not improve from 0.29783\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - binary_accuracy: 0.8748 - loss: 0.2912 - val_binary_accuracy: 0.8690 - val_loss: 0.2997 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.8757 - loss: 0.2889\n",
      "Epoch 39: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - binary_accuracy: 0.8757 - loss: 0.2889 - val_binary_accuracy: 0.8708 - val_loss: 0.3003 - learning_rate: 5.0000e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.8760 - loss: 0.2894\n",
      "Epoch 40: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - binary_accuracy: 0.8760 - loss: 0.2894 - val_binary_accuracy: 0.8704 - val_loss: 0.2999 - learning_rate: 5.0000e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.8753 - loss: 0.2884\n",
      "Epoch 41: val_loss did not improve from 0.29783\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - binary_accuracy: 0.8753 - loss: 0.2884 - val_binary_accuracy: 0.8698 - val_loss: 0.2997 - learning_rate: 5.0000e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.8755 - loss: 0.2888\n",
      "Epoch 42: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - binary_accuracy: 0.8755 - loss: 0.2887 - val_binary_accuracy: 0.8702 - val_loss: 0.2997 - learning_rate: 2.5000e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.8752 - loss: 0.2888\n",
      "Epoch 43: val_loss did not improve from 0.29783\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - binary_accuracy: 0.8752 - loss: 0.2888 - val_binary_accuracy: 0.8698 - val_loss: 0.3005 - learning_rate: 2.5000e-06\n",
      "Epoch 44/50\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    ),\n",
    "\n",
    "    ReduceLROnPlateau(\n",
    "        monitor = \"val_loss\",\n",
    "        factor = 0.5,\n",
    "        patience = 3,\n",
    "        verbose = 1,\n",
    "        min_lr = 1e-7\n",
    "    ),\n",
    "    # EarlyStopping(\n",
    "    #     monitor = 'val_loss',\n",
    "    #     patience = 5,\n",
    "    #     restore_best_weights =True\n",
    "    # )\n",
    "    \n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch = 31,\n",
    "    epochs=50,\n",
    "    # batch_size = 8,\n",
    "    verbose = 1,\n",
    "    callbacks = my_callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803bae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 17:55:19.795715: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 396 bytes spill stores, 332 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.8679 - loss: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 17:55:38.768105: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 225ms/step - binary_accuracy: 0.8679 - loss: 0.2999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"../data/numpy/X_test.npy\")\n",
    "Y_test = np.load(\"../data/numpy/Y_test.npy\")\n",
    "results = model.evaluate(X_test,Y_test,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f0939fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "(3, 7)\n",
      "[[0.09601673 0.14201155 0.00136412 0.27182674 0.02983427 0.04969598\n",
      "  0.39611477]\n",
      " [0.18241608 0.2976508  0.00535467 0.5710748  0.00205775 0.00094726\n",
      "  0.04155317]\n",
      " [0.1625095  0.16413555 0.07197529 0.39996296 0.00268529 0.00431573\n",
      "  0.07996302]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:3])\n",
    "print(predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f73775b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511e422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import RandomFlip,RandomRotation,RandomTranslation,RandomZoom\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     RandomFlip(\"horizontal\"),\n",
    "#     RandomTranslation(0.1,0.1),\n",
    "#     RandomZoom(0.1),\n",
    "#     RandomRotation(0.05)\n",
    "# ])\n",
    "\n",
    "\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# # Use mixed precision\n",
    "# # https://keras.io/api/mixed_precision/\n",
    "# set_global_policy('mixed_float16')\n",
    "\n",
    "# # Clear GPU memory\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "#     base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "#     inputs = layers.Input(shape=(224,224,1))\n",
    "#     x = data_augmentation(inputs)\n",
    "#     x = layers.Conv2D(3,(3,3), padding = 'same')(x)\n",
    "#     x = base_model(x)\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "#     # base_model.\n",
    "#     outputs = layers.Dense(7,activation='sigmoid')(x)\n",
    "\n",
    "#     base_model = model.layers[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # model.add\n",
    "\n",
    "#     model = models.Model(inputs,outputs)\n",
    "#     for layer in base_model.layers[:210]:\n",
    "#         layer.trainable =False\n",
    "\n",
    "\n",
    "#     for i, layer in enumerate(base_model.layers):\n",
    "#         if layer.trainable:\n",
    "#             print(i, layer.name, layer.trainable)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e252507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 block6d_dwconv True\n",
      "211 block6d_bn True\n",
      "212 block6d_activation True\n",
      "213 block6d_se_squeeze True\n",
      "214 block6d_se_reshape True\n",
      "215 block6d_se_reduce True\n",
      "216 block6d_se_expand True\n",
      "217 block6d_se_excite True\n",
      "218 block6d_project_conv True\n",
      "219 block6d_project_bn True\n",
      "220 block6d_drop True\n",
      "221 block6d_add True\n",
      "222 block7a_expand_conv True\n",
      "223 block7a_expand_bn True\n",
      "224 block7a_expand_activation True\n",
      "225 block7a_dwconv True\n",
      "226 block7a_bn True\n",
      "227 block7a_activation True\n",
      "228 block7a_se_squeeze True\n",
      "229 block7a_se_reshape True\n",
      "230 block7a_se_reduce True\n",
      "231 block7a_se_expand True\n",
      "232 block7a_se_excite True\n",
      "233 block7a_project_conv True\n",
      "234 block7a_project_bn True\n",
      "235 top_conv True\n",
      "236 top_bn True\n",
      "237 top_activation True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,967</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m8,967\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,058,568</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,058,568\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,502,853</span> (5.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,502,853\u001b[0m (5.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,555,715</span> (9.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,555,715\u001b[0m (9.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomTranslation, RandomZoom\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "    RandomZoom(0.1),\n",
    "    RandomRotation(0.05)\n",
    "])\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "set_global_policy('mixed_float16')\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "    base_model.trainable = True  \n",
    "\n",
    "    inputs = layers.Input(shape=(224, 224, 1))\n",
    "    # x = data_augmentation(inputs)\n",
    "    x = layers.Conv2D(3, (3, 3), padding='same')(inputs)  \n",
    "    x = base_model(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(7, activation='sigmoid', dtype='float32')(x)  # Force float32 for final layer\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    # Now freeze first 210 layers of base_model\n",
    "    for layer in base_model.layers[:210]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        if layer.trainable:\n",
    "            print(i, layer.name, layer.trainable)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85408c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9416f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n",
    "Y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model2_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    ),\n",
    "\n",
    "    ReduceLROnPlateau(\n",
    "        monitor = \"val_loss\",\n",
    "        factor = 0.5,\n",
    "        patience = 5,\n",
    "        verbose = 1,\n",
    "        min_lr = 1e-7\n",
    "    )\n",
    "    # EarlyStopping(\n",
    "    #     monitor = 'val_loss',\n",
    "    #     patience = 5,\n",
    "    #     restore_best_weights =True\n",
    "    # )\n",
    "    \n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=25,\n",
    "        verbose=1,\n",
    "        callbacks=my_callbacks\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
