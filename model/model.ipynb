{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ad3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.appliications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC,Precision,Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,Tensorboard\n",
    "\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images\n",
    "# base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "# inputs = layers.Input(shape=(224,224,1))\n",
    "# x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "# x = base_model(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# outputs = layers.Dense(8,activation='sigmoid')(x)\n",
    "\n",
    "# model = models.Model(inputs,outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a26607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746125894.784073    1125 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1746125894.786688    1125 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,967</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m8,967\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,058,568</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,058,568\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,707,885</span> (14.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,707,885\u001b[0m (14.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,683</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m350,683\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Use mixed precision\n",
    "# https://keras.io/api/mixed_precision/\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear GPU memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "    inputs = layers.Input(shape=(224,224,1))\n",
    "    x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "    # x = layers.Lambda(lambda x: tf.repeat(x, 3, axis=-1))(inputs)\n",
    "    x = base_model(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    # x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "    # base_model.\n",
    "    outputs = layers.Dense(7,activation='sigmoid')(x)\n",
    "    for layer in base_model.layers[:-119]:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "    # model.add\n",
    "\n",
    "    model = models.Model(inputs,outputs)\n",
    "\n",
    "    \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674090df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(base_model.layers[-119:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45b92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"\n",
    "#                                                                       # , \"val_accuracy\"\n",
    "#                                                                     #   ,AUC(), Precision(),Recall()\n",
    "#                                                                       ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.path.exists('/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a25fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.load(\"../data/numpy/X_train.npy\")\n",
    "Y_train = np.load(\"../data/numpy/Y_train.npy\")\n",
    "\n",
    "X_val = np.load(\"../data/numpy/X_valid.npy\")\n",
    "Y_val = np.load(\"../data/numpy/Y_valid.npy\")\n",
    "\n",
    "\n",
    "# X_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_train.npy\")\n",
    "# Y_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy\")\n",
    "\n",
    "# X_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_valid.npy\")\n",
    "# Y_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_valid.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc60e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d2f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 0.8576 - loss: 0.3423\n",
      "Epoch 1: val_loss improved from inf to 0.33700, saving model to ../checkpoint/model_01.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 88ms/step - binary_accuracy: 0.8576 - loss: 0.3423 - val_binary_accuracy: 0.8582 - val_loss: 0.3370\n",
      "Epoch 2/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8581 - loss: 0.3395\n",
      "Epoch 2: val_loss improved from 0.33700 to 0.32906, saving model to ../checkpoint/model_02.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8581 - loss: 0.3395 - val_binary_accuracy: 0.8600 - val_loss: 0.3291\n",
      "Epoch 3/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.8585 - loss: 0.3384\n",
      "Epoch 3: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 64ms/step - binary_accuracy: 0.8585 - loss: 0.3384 - val_binary_accuracy: 0.8598 - val_loss: 0.3315\n",
      "Epoch 4/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.8592 - loss: 0.3367\n",
      "Epoch 4: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - binary_accuracy: 0.8592 - loss: 0.3367 - val_binary_accuracy: 0.8543 - val_loss: 0.3392\n",
      "Epoch 5/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8589 - loss: 0.3351\n",
      "Epoch 5: val_loss did not improve from 0.32906\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 65ms/step - binary_accuracy: 0.8589 - loss: 0.3351 - val_binary_accuracy: 0.8580 - val_loss: 0.3304\n",
      "Epoch 6/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.8597 - loss: 0.3327\n",
      "Epoch 6: val_loss improved from 0.32906 to 0.32865, saving model to ../checkpoint/model_06.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 65ms/step - binary_accuracy: 0.8597 - loss: 0.3327 - val_binary_accuracy: 0.8573 - val_loss: 0.3286\n",
      "Epoch 7/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8602 - loss: 0.3317\n",
      "Epoch 7: val_loss improved from 0.32865 to 0.32458, saving model to ../checkpoint/model_07.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8602 - loss: 0.3317 - val_binary_accuracy: 0.8618 - val_loss: 0.3246\n",
      "Epoch 8/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8602 - loss: 0.3294\n",
      "Epoch 8: val_loss improved from 0.32458 to 0.32229, saving model to ../checkpoint/model_08.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8602 - loss: 0.3294 - val_binary_accuracy: 0.8580 - val_loss: 0.3223\n",
      "Epoch 9/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8617 - loss: 0.3267\n",
      "Epoch 9: val_loss improved from 0.32229 to 0.32027, saving model to ../checkpoint/model_09.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8617 - loss: 0.3267 - val_binary_accuracy: 0.8602 - val_loss: 0.3203\n",
      "Epoch 10/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8608 - loss: 0.3263\n",
      "Epoch 10: val_loss improved from 0.32027 to 0.31793, saving model to ../checkpoint/model_10.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8608 - loss: 0.3263 - val_binary_accuracy: 0.8588 - val_loss: 0.3179\n",
      "Epoch 11/15\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8620 - loss: 0.3239\n",
      "Epoch 11: val_loss improved from 0.31793 to 0.31459, saving model to ../checkpoint/model_11.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8620 - loss: 0.3239 - val_binary_accuracy: 0.8594 - val_loss: 0.3146\n",
      "Epoch 12/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8617 - loss: 0.3238\n",
      "Epoch 12: val_loss improved from 0.31459 to 0.31068, saving model to ../checkpoint/model_12.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - binary_accuracy: 0.8617 - loss: 0.3238 - val_binary_accuracy: 0.8651 - val_loss: 0.3107\n",
      "Epoch 13/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.8631 - loss: 0.3220\n",
      "Epoch 13: val_loss did not improve from 0.31068\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - binary_accuracy: 0.8631 - loss: 0.3220 - val_binary_accuracy: 0.8616 - val_loss: 0.3117\n",
      "Epoch 14/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8626 - loss: 0.3205\n",
      "Epoch 14: val_loss improved from 0.31068 to 0.30636, saving model to ../checkpoint/model_14.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8626 - loss: 0.3204 - val_binary_accuracy: 0.8686 - val_loss: 0.3064\n",
      "Epoch 15/15\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.8638 - loss: 0.3174\n",
      "Epoch 15: val_loss did not improve from 0.30636\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 66ms/step - binary_accuracy: 0.8638 - loss: 0.3174 - val_binary_accuracy: 0.8655 - val_loss: 0.3070\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    )\n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    # batch_size = 8,\n",
    "    verbose = 1,\n",
    "    callbacks = my_callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data = (X_val, Y_val),\n",
    "#     epochs = 10,\n",
    "#     batch_size = 8,\n",
    "#     verbose = 1\n",
    "#     )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=80,\n",
    "#     # batch_size = 8,\n",
    "#     verbose = 1,\n",
    "#     callbacks = my_callbacks\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.load(\"../data/numpy/X_test.npy\")\n",
    "# Y_test = np.load(\"../data/numpy/Y_test.npy\")\n",
    "# results = model.evaluate(X_test,Y_test,batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d149807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test[:3])\n",
    "# print(predictions.shape)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.load_model(\"../checkpoint/model_02.keras\")\n",
    "# print(len(model.layers))\n",
    "# # for layer in models.layer[:]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue\n",
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    )\n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "model = load_model(\"../checkpoint/model_14.keras\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch = 14,\n",
    "    epochs=30,\n",
    "    # batch_size = 8,\n",
    "    verbose = 1,\n",
    "    callbacks = my_callbacks\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
