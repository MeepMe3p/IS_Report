{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "47ad3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.appliications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC,Precision,Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,Tensorboard\n",
    "\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3c7a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images\n",
    "# base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "# inputs = layers.Input(shape=(224,224,1))\n",
    "# x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "# x = base_model(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# outputs = layers.Dense(8,activation='sigmoid')(x)\n",
    "\n",
    "# model = models.Model(inputs,outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a26607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,967</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m8,967\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,058,568</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,058,568\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,016,545</span> (15.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,016,545\u001b[0m (15.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,023</span> (164.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,023\u001b[0m (164.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Use mixed precision\n",
    "# https://keras.io/api/mixed_precision/\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear GPU memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    base_model = EfficientNetB0(include_top=False,weights = 'imagenet')\n",
    "\n",
    "    inputs = layers.Input(shape=(224,224,1))\n",
    "    x = layers.Conv2D(3,(3,3), padding = 'same')(inputs)\n",
    "    # x = layers.Lambda(lambda x: tf.repeat(x, 3, axis=-1))(inputs)\n",
    "    x = base_model(x)\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "    # base_model.\n",
    "    outputs = layers.Dense(7,activation='sigmoid')(x)\n",
    "\n",
    "    # model.add\n",
    "\n",
    "    model = models.Model(inputs,outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f6f0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics = [\"binary_accuracy\"\n",
    "                                                                      # , \"val_accuracy\"\n",
    "                                                                    #   ,AUC(), Precision(),Recall()\n",
    "                                                                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "363c6227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists('/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a25fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train = np.load(\"../data/numpy/X_train.npy\")\n",
    "# Y_train = np.load(\"../data/numpy/Y_train.npy\")\n",
    "\n",
    "# X_val = np.load(\"../data/numpy/X_valid.npy\")\n",
    "# Y_val = np.load(\"../data/numpy/Y_valid.npy\")\n",
    "\n",
    "\n",
    "X_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_train.npy\")\n",
    "Y_train = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_train.npy\")\n",
    "\n",
    "X_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/X_valid.npy\")\n",
    "Y_val = np.load(\"/home/aifablab/projects/ElijahKun/TestOne/IS_Report/data/numpy/Y_valid.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5cc60e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 1)\n",
      "(12589, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f98d2f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9652 - loss: 0.0889\n",
      "Epoch 1: val_loss improved from inf to 0.70486, saving model to ../checkpoint/model_01.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 36ms/step - binary_accuracy: 0.9652 - loss: 0.0889 - val_binary_accuracy: 0.7987 - val_loss: 0.7049\n",
      "Epoch 2/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9710 - loss: 0.0761\n",
      "Epoch 2: val_loss improved from 0.70486 to 0.65522, saving model to ../checkpoint/model_02.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9710 - loss: 0.0761 - val_binary_accuracy: 0.8240 - val_loss: 0.6552\n",
      "Epoch 3/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9740 - loss: 0.0676\n",
      "Epoch 3: val_loss did not improve from 0.65522\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9740 - loss: 0.0676 - val_binary_accuracy: 0.6393 - val_loss: 0.9114\n",
      "Epoch 4/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9761 - loss: 0.0642\n",
      "Epoch 4: val_loss improved from 0.65522 to 0.55837, saving model to ../checkpoint/model_04.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - binary_accuracy: 0.9761 - loss: 0.0642 - val_binary_accuracy: 0.7633 - val_loss: 0.5584\n",
      "Epoch 5/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9785 - loss: 0.0561\n",
      "Epoch 5: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9785 - loss: 0.0561 - val_binary_accuracy: 0.7490 - val_loss: 0.6622\n",
      "Epoch 6/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9784 - loss: 0.0575\n",
      "Epoch 6: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9784 - loss: 0.0575 - val_binary_accuracy: 0.8173 - val_loss: 0.7625\n",
      "Epoch 7/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9810 - loss: 0.0501\n",
      "Epoch 7: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9810 - loss: 0.0501 - val_binary_accuracy: 0.8105 - val_loss: 0.6614\n",
      "Epoch 8/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9815 - loss: 0.0500\n",
      "Epoch 8: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9815 - loss: 0.0500 - val_binary_accuracy: 0.8007 - val_loss: 2.2477\n",
      "Epoch 9/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9829 - loss: 0.0467\n",
      "Epoch 9: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9829 - loss: 0.0467 - val_binary_accuracy: 0.8508 - val_loss: 0.5856\n",
      "Epoch 10/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9846 - loss: 0.0415\n",
      "Epoch 10: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9846 - loss: 0.0415 - val_binary_accuracy: 0.8257 - val_loss: 0.6935\n",
      "Epoch 11/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9835 - loss: 0.0441\n",
      "Epoch 11: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9835 - loss: 0.0441 - val_binary_accuracy: 0.8304 - val_loss: 0.7203\n",
      "Epoch 12/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9860 - loss: 0.0379\n",
      "Epoch 12: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9860 - loss: 0.0379 - val_binary_accuracy: 0.8345 - val_loss: 0.8465\n",
      "Epoch 13/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9857 - loss: 0.0392\n",
      "Epoch 13: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9857 - loss: 0.0391 - val_binary_accuracy: 0.8224 - val_loss: 0.8237\n",
      "Epoch 14/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9869 - loss: 0.0355\n",
      "Epoch 14: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9869 - loss: 0.0355 - val_binary_accuracy: 0.8302 - val_loss: 0.6599\n",
      "Epoch 15/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9884 - loss: 0.0332\n",
      "Epoch 15: val_loss did not improve from 0.55837\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - binary_accuracy: 0.9884 - loss: 0.0332 - val_binary_accuracy: 0.8371 - val_loss: 0.8315\n",
      "Epoch 16/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9884 - loss: 0.0324\n",
      "Epoch 16: val_loss improved from 0.55837 to 0.54924, saving model to ../checkpoint/model_16.keras\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - binary_accuracy: 0.9884 - loss: 0.0324 - val_binary_accuracy: 0.8287 - val_loss: 0.5492\n",
      "Epoch 17/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - binary_accuracy: 0.9862 - loss: 0.0365\n",
      "Epoch 17: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 31ms/step - binary_accuracy: 0.9862 - loss: 0.0365 - val_binary_accuracy: 0.8287 - val_loss: 0.7856\n",
      "Epoch 18/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9901 - loss: 0.0261\n",
      "Epoch 18: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 52ms/step - binary_accuracy: 0.9901 - loss: 0.0261 - val_binary_accuracy: 0.8236 - val_loss: 0.8097\n",
      "Epoch 19/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9892 - loss: 0.0315\n",
      "Epoch 19: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - binary_accuracy: 0.9892 - loss: 0.0315 - val_binary_accuracy: 0.8357 - val_loss: 0.9182\n",
      "Epoch 20/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9891 - loss: 0.0313\n",
      "Epoch 20: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - binary_accuracy: 0.9891 - loss: 0.0313 - val_binary_accuracy: 0.8206 - val_loss: 1.0282\n",
      "Epoch 21/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9903 - loss: 0.0274\n",
      "Epoch 21: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - binary_accuracy: 0.9903 - loss: 0.0274 - val_binary_accuracy: 0.8122 - val_loss: 1.1228\n",
      "Epoch 22/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9894 - loss: 0.0298\n",
      "Epoch 22: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.9894 - loss: 0.0298 - val_binary_accuracy: 0.8279 - val_loss: 0.6844\n",
      "Epoch 23/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9923 - loss: 0.0209\n",
      "Epoch 23: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.9923 - loss: 0.0209 - val_binary_accuracy: 0.8418 - val_loss: 0.6810\n",
      "Epoch 24/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9903 - loss: 0.0259\n",
      "Epoch 24: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.9903 - loss: 0.0259 - val_binary_accuracy: 0.7860 - val_loss: 1.3688\n",
      "Epoch 25/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9905 - loss: 0.0263\n",
      "Epoch 25: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.9905 - loss: 0.0263 - val_binary_accuracy: 0.8375 - val_loss: 0.7331\n",
      "Epoch 26/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9916 - loss: 0.0235\n",
      "Epoch 26: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - binary_accuracy: 0.9916 - loss: 0.0234 - val_binary_accuracy: 0.8291 - val_loss: 0.9400\n",
      "Epoch 27/80\n",
      "\u001b[1m1573/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9920 - loss: 0.0233\n",
      "Epoch 27: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - binary_accuracy: 0.9920 - loss: 0.0233 - val_binary_accuracy: 0.8422 - val_loss: 0.6073\n",
      "Epoch 28/80\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9911 - loss: 0.0224\n",
      "Epoch 28: val_loss did not improve from 0.54924\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - binary_accuracy: 0.9911 - loss: 0.0224 - val_binary_accuracy: 0.8202 - val_loss: 0.8754\n",
      "Epoch 29/80\n",
      "\u001b[1m 411/1574\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 29ms/step - binary_accuracy: 0.9944 - loss: 0.0180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(\u001b[32m8\u001b[39m)\n\u001b[32m     12\u001b[39m val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(\u001b[32m8\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch_size = 8,\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_callbacks\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor = \"val_loss\" ,# commonly uses valloss why? cuz secret\n",
    "        verbose =1,\n",
    "        filepath = \"../checkpoint/model_{epoch:02d}.keras\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False\n",
    "    )\n",
    "]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=80,\n",
    "    # batch_size = 8,\n",
    "    verbose = 1,\n",
    "    callbacks = my_callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e57f6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data = (X_val, Y_val),\n",
    "#     epochs = 10,\n",
    "#     batch_size = 8,\n",
    "#     verbose = 1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f1a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:34:30.533431: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-29 13:34:30.791163: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 1672 bytes spill stores, 1640 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.8059 - loss: 0.4465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:34:42.049199: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-29 13:34:42.261240: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2044', 1484 bytes spill stores, 1484 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - binary_accuracy: 0.8057 - loss: 0.4465\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"../data/numpy/X_test.npy\")\n",
    "Y_test = np.load(\"../data/numpy/Y_test.npy\")\n",
    "results = model.evaluate(X_test,Y_test,batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d149807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "(3, 7)\n"
     ]
    }
   ],
   "source": [
    "# predictions = model.predict(X_test[:3])\n",
    "# print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4bf6b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "models.load_model(\"../checkpoint/model_02.keras\")\n",
    "print(len(model.layers))\n",
    "# for layer in models.layer[:]:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
